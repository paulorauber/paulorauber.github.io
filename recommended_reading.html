<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#ffffff">
  <meta name="description" content="Recommended Reading - Paulo Rauber.">
  <title>Recommended Reading - Paulo Rauber</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <a href="#main" class="skip-link">Skip to main content</a>

  <header>
    <div class="header-text">
      <h1>Paulo Rauber</h1>
      <p class="contact">
        Lecturer in Artificial Intelligence<br>
        Queen Mary University of London<br>
        <a href="mailto:p.rauber@qmul.ac.uk">p.rauber@qmul.ac.uk</a>
      </p>
      <nav>
        <a href="index.html">About</a>
        <a href="work.html">Work</a>
      </nav>
    </div>
    <img src="files/images/profile.jpg" alt="Paulo Rauber" class="profile-pic" width="150" height="150">
  </header>

  <main id="main">
    <h2>Recommended reading</h2>

    <p>I recommend the following references to students interested in artificial intelligence research.</p>

    <p>My current research is focused on developing principled but scalable Bayesian reinforcement learning methods. A typical Bayesian reinforcement learning method represents its knowledge about an environment by a probability distribution over (one-step dynamics) models and uses this knowledge to seek optimal actions. If you would like to pursue a PhD under my supervision, please skim the survey highlighted below and my <a href="index.html">selected publications</a>.</p>

    <h3>PhD level</h3>
    <p>Bayesian reinforcement learning (<a href="files/notes/mtbrl.pdf">notes</a>):</p>
    <ul>
      <li>M. Ghavamzadeh, S. Mannor, J. Pineau, A. Tamar. <span class="highlight"><em>"Bayesian Reinforcement Learning: A Survey"</em></span>. Foundations and Trends in Machine Learning, 2015.</li>
    </ul>
    <p>Measure-theoretic probability (<a href="files/notes/probability.pdf">notes</a>):</p>
    <ul>
      <li>D. Pollard. <em>"A User's Guide to Measure Theoretic Probability"</em>. Cambridge University Press, 2010.</li>
    </ul>
    <p>Reinforcement learning theory (<a href="files/notes/rl_theory.pdf">notes</a>):</p>
    <ul>
      <li>T. Lattimore, C. Szepesv√°ri. <em>"Bandit Algorithms"</em>. Cambridge University Press, 2020.</li>
    </ul>
    <p>Artificial intelligence:</p>
    <ul>
      <li>S. Legg. <em>"Machine Super Intelligence"</em>. PhD thesis, 2008.</li>
    </ul>

    <h3>MSc level</h3>
    <p>Machine learning (<a href="files/notes/machine_learning.pdf">notes</a> and <a href="files/notes/probabilistic_graphical_models.pdf">notes</a>):</p>
    <ul>
      <li>C. Bishop. <em>"Pattern Recognition and Machine Learning"</em>. Springer-Verlag, 2007.</li>
      <li>K.P. Murphy. <em>"Probabilistic Machine Learning: An Introduction"</em>. MIT Press, 2022.</li>
      <li>M.J. Kochenderfer, T.A. Wheeler, K.H. Wray. <em>"Algorithms for Decision Making"</em>. MIT Press, 2022.</li>
    </ul>
    <p>Neural networks (<a href="files/notes/neural_networks.pdf">notes</a>):</p>
    <ul>
      <li>S.J.D. Prince. <em>"Understanding Deep Learning"</em>. MIT Press, 2023.</li>
    </ul>

    <h3>BSc level</h3>
    <p>Programming:</p>
    <ul>
      <li>E. Matthes. <em>"Python Crash Course"</em>. No Starch Press, 2023.</li>
      <li>K.N. King. <em>"C Programming: A Modern Approach"</em>. W. W. Norton & Company, 2008.</li>
    </ul>
    <p>Computer design:</p>
    <ul>
      <li>D.A. Patterson, J.L. Hennessy. <em>"Computer Organization and Design: RISC-V Edition"</em>. Morgan Kaufmann, 2020.</li>
    </ul>
    <p>Mathematical proof:</p>
    <ul>
      <li>D.J. Velleman. <em>"How to Prove It: A Structured Approach"</em>. Cambridge University Press, 2019.</li>
    </ul>
    <p>Calculus (<a href="files/notes/calculus.pdf">notes</a>):</p>
    <ul>
      <li>J. Stewart. <em>"Calculus: Early Transcendentals"</em>. Brooks/Cole, 2011.</li>
    </ul>
    <p>Algorithms:</p>
    <ul>
      <li>T.H. Cormen, C.E. Leiserson, R. Rivest, C. Stein. <em>"Introduction to Algorithms"</em>. MIT Press, 2022.</li>
    </ul>
    <p>Theory of computation:</p>
    <ul>
      <li>T. Sipser. <em>"Introduction to the Theory of Computation"</em>. Course Technology, 2012.</li>
    </ul>
    <p>Analysis:</p>
    <ul>
      <li>T. Tao. <em>"Analysis I"</em>. Springer, 2022.</li>
    </ul>
    <p>Linear algebra (<a href="files/notes/linear_algebra.pdf">notes</a>):</p>
    <ul>
      <li>S. Axler. <em>"Linear Algebra Done Right"</em>. Springer, 1997.</li>
    </ul>
    <p>Probability (<a href="files/notes/machine_learning.pdf">notes</a>, Sec. 2):</p>
    <ul>
      <li>D.P. Bertsekas, J.N. Tsitsiklis. <em>"Introduction to Probability"</em>. Athena Scientific, 2008.</li>
    </ul>
    <p>Artificial intelligence:</p>
    <ul>
      <li>S. Russell, P. Norvig. <em>"Artificial Intelligence: A Modern Approach"</em>. Pearson, 2021.</li>
    </ul>
    <p>Reinforcement learning (<a href="files/notes/reinforcement_learning.pdf">notes</a>):</p>
    <ul>
      <li>R.S. Sutton, A.G. Barto. <em>"Reinforcement Learning: An Introduction"</em>. MIT Press, 2020.</li>
    </ul>
  </main>
</body>
</html>
